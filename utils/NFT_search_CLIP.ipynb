{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sswang/anaconda3/envs/img_matching/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 427,944,193\n",
      "Input resolution: 336\n",
      "Context length: 77\n",
      "Vocab size: 49408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=336, interpolation=bicubic, max_size=None, antialias=None)\n",
       "    CenterCrop(size=(336, 336))\n",
       "    <function _convert_image_to_rgb at 0x7efb11775550>\n",
       "    ToTensor()\n",
       "    Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from pkg_resources import packaging\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from pathlib import Path\n",
    "import clip.clip as clip\n",
    "from PIL import Image\n",
    "import os \n",
    "device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model, preprocess = clip.load(\"ViT-B/32\")\n",
    "model, preprocess = clip.load(name=\"/data/sswang/NFT_search/models/ViT-L-14-336px.pt\", device=device)\n",
    "# 将模型加载到GPU中并切换到评估模式\n",
    "# model.cuda(device).eval()\n",
    "model.eval()\n",
    "input_resolution = model.visual.input_resolution\n",
    "context_length = model.context_length\n",
    "vocab_size = model.vocab_size\n",
    "\n",
    "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
    "print(\"Input resolution:\", input_resolution)\n",
    "print(\"Context length:\", context_length)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "\n",
    "preprocess"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.stack(images) 函数将一个由多个图像组成的列表 images 沿着一个新轴（默认为 0）进行连接，生成一个新的数组。这个新的数组的维度比原来的数组多了一个维度，用于存储连接后的图像。如果 images 中的每个图像的尺寸都相同，那么连接后的数组的第一个维度将是 len(images)，第二个维度将是图像的高度，第三个维度将是图像的宽度，第四个维度将是图像的通道数。\n",
    "\n",
    "这行代码是从一个图像列表中创建了一个 PyTorch 张量 image_input。np.stack(images) 函数沿着一个新轴（默认为 0）将图像列表进行连接。然后，torch.tensor() 将连接后的图像列表转换为 PyTorch 张量。.cuda() 方法将张量移动到 GPU 上进行加速运算。\n",
    "\n",
    "\n",
    "`img_features` 是一个存放了100个图像的特征向量的列表。归一化操作 `img_features /= img_features.norm(dim=-1, keepdim=True)` 用于将特征向量进行归一化处理。\n",
    "\n",
    "下面是对归一化操作的细节解释：\n",
    "\n",
    "1. `img_features.norm(dim=-1, keepdim=True)`：这部分代码计算了 `img_features` 列表中每个特征向量的范数（即向量的长度）。`dim=-1` 表示在最后一个维度上进行计算，即对每个特征向量的元素进行平方求和，然后取平方根。\n",
    "\n",
    "2. `keepdim=True`：这部分代码保持结果的维度与输入的 `img_features` 保持一致。这样，计算的结果将是一个具有相同形状的张量，每个特征向量的范数都被保留在一个单独的维度中。\n",
    "\n",
    "3. `img_features /= img_features.norm(dim=-1, keepdim=True)`：这部分代码进行了归一化操作。通过除以每个特征向量的范数，将每个特征向量的长度缩放到1。`/=` 是就地除法运算符，它将结果保存回 `img_features` 列表中。\n",
    "\n",
    "归一化操作的目的是将特征向量的尺度标准化，使其具有相似的大小。这有助于确保特征向量在计算相似度或进行其他操作时具有一致的权重和规模。通过将特征向量缩放到单位长度，可以使它们在相似度计算中具有更好的可比性和一致性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def check_dir(dir_path):\n",
    "    \"\"\"\n",
    "    检查文件夹路径是否存在，不存在则创建\n",
    "\n",
    "    Args:\n",
    "        dir_path (str): 待检查的文件夹路径\n",
    "    \"\"\"\n",
    "    if not os.path.exists(dir_path):\n",
    "        try:\n",
    "            os.makedirs(dir_path)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "def load_json(json_path):\n",
    "    \"\"\"\n",
    "    以只读的方式打开json文件\n",
    "\n",
    "    Args:\n",
    "        config_path: json文件路径\n",
    "\n",
    "    Returns:\n",
    "        A dictionary\n",
    "\n",
    "    \"\"\"\n",
    "    with open(json_path, 'r', encoding='UTF-8') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def save_json(save_path, data):\n",
    "    \"\"\"\n",
    "    Saves the data to a file with the given filename in the given path\n",
    "\n",
    "    Args:\n",
    "        :param save_path: The path to the folder where you want to save the file\n",
    "        :param filename: The name of the file to save\n",
    "        :param data: The data to be saved\n",
    "\n",
    "    \"\"\"\n",
    "    with open(save_path, 'w', encoding='UTF-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "def is_str_Length_valid(str_list) -> bool:\n",
    "    \"\"\"\n",
    "    判断字符串长度是否超过77\n",
    "\n",
    "    Args:\n",
    "        str_list (list): 字符串列表\n",
    "\n",
    "    Returns:\n",
    "        bool: 是否超过77\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for str in str_list:\n",
    "            clip.tokenize(str)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def tensorlize_imgs(model, img_path_list) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    使用模型提取图片特征，返回图片特征向量列表\n",
    "\n",
    "    Args:\n",
    "        img_path_list (list): 图片路径列表\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: 图片特征向量列表\n",
    "    \"\"\"\n",
    "\n",
    "    images = []\n",
    "    for img_path in img_path_list:\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "            # 首先将图片预处理成模型需要的格式\n",
    "        images.append(preprocess(image))\n",
    "        # 把图片加载进cuda中\n",
    "    image_input = torch.tensor(np.stack(images)).cuda(device=device)\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image_input).float()\n",
    "        # 将image_features从GPU移动到CPU，并返回\n",
    "        return image_features.cpu()\n",
    "            \n",
    "\n",
    "def tensorlize_texts(model, text_tokens_list) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    使用模型提取单句文本特征，返回文本特征向量列表\n",
    "\n",
    "    Args:\n",
    "        text_tokens_list (list): 文本列表\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: 文本特征向量列表\n",
    "    \"\"\"\n",
    "    text_tokens = clip.tokenize(text_tokens_list).cuda(device=device)\n",
    "    with torch.no_grad():\n",
    "        text_features = model.encode_text(text_tokens).float()\n",
    "        # 将text_features从GPU移动到CPU，并返回\n",
    "        # print(text_features.shape)\n",
    "        return text_features.cpu().numpy().tolist()\n",
    "    \n",
    "def load_img_tensor(device, imgTensor_path):\n",
    "    \"\"\"\n",
    "    加载图片的tensor 向量到指定cuda中\n",
    "\n",
    "    Args:\n",
    "        device (str): cuda\n",
    "        img_path (str): 图片tensor路径\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: 图片特征向量\n",
    "    \"\"\"\n",
    "    # 加载json文件\n",
    "    NFT_tensor_data = load_json(imgTensor_path)\n",
    "    image_features = NFT_tensor_data['image_features']\n",
    "    image_tensors = torch.tensor(image_features).to(device)\n",
    "    return image_tensors\n",
    "\n",
    "def load_des_tensor(device, desTensor_path):\n",
    "    \"\"\"\n",
    "    加载描述的tensor 向量到指定cuda中\n",
    "\n",
    "    Args:\n",
    "        device (str): cuda\n",
    "        img_path (str): 描述的tensor路径\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: 图片特征向量\n",
    "    \"\"\"\n",
    "    # 加载json文件\n",
    "    NFT_tensor_data = load_json(desTensor_path)\n",
    "    des_features = NFT_tensor_data['des_tensors']\n",
    "    \n",
    "    # # 确保每个元素都被转换为张量\n",
    "    # des_tensors = [torch.tensor(feature).to(device) for feature in des_features]\n",
    "    # for des_tensor in des_tensors:\n",
    "    #     print(des_tensor.shape)\n",
    "    \n",
    "    des_tensors = torch.tensor(des_features).to(device)\n",
    "    for des_tensor in des_tensors:\n",
    "        print(des_tensor.shape)\n",
    "\n",
    "    # 将所有张量堆叠在一起\n",
    "    des_tensors = torch.stack(tuple(des_tensors), dim=1)\n",
    "\n",
    "    print(des_tensors.shape)\n",
    "    return des_tensors\n",
    "\n",
    "def slide_window_tokenizer(text, window_size, step_size) -> list:\n",
    "    \"\"\"\n",
    "    为了处理长度超过77的句子，这里设计滑动窗口分词\n",
    "\n",
    "    Args:\n",
    "        text (str): 将要被拆分的句子\n",
    "\n",
    "    Returns:\n",
    "        list: 拆分后的句子列表\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    sentences = []\n",
    "    slide_window_list = [i for i in range(0, len(words) - 1, step_size) if i + step_size < len(words) - 1]\n",
    "    for i in slide_window_list:\n",
    "        sentence = ' '.join(words[i:i+window_size])\n",
    "        sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "def calculate_cosine_similarity_topk(img_features, des_features, k = 10) -> tuple:\n",
    "    \"\"\"\n",
    "    计算图片特征和描述特征的余弦相似度，并返回topk的结果\n",
    "\n",
    "    Args:\n",
    "        img_features (torch.tensor): 图像特征向量\n",
    "        des_features (torch.tensor): 描述特征向量\n",
    "        k (int, optional): 前k位结果. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (topk的相似度，topk的索引)\n",
    "    \"\"\"\n",
    "    # 对每一个特征向量进行归一化，使其范数为1\n",
    "    img_features /= img_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    # 归一化描述特征\n",
    "    des_features /= des_features.norm(dim=-1, keepdim=True)\n",
    "    # similarity = des_features.cpu().numpy() @ img_features.cpu().numpy().T\n",
    "    # 每个图像向量都与100个文本向量计算余弦相似度，然后计算100次\n",
    "    text_probs = (100.0 * img_features @ des_features.T).softmax(dim=-1)\n",
    "    top_probs, top_labels = text_probs.cpu().topk(k, dim=-1)\n",
    "    return top_probs, top_labels\n",
    "\n",
    "\n",
    "def slide_window_tokenizer(text, window_size, step_size) -> list:\n",
    "    \"\"\"\n",
    "    为了处理长度超过77的句子，这里设计滑动窗口分词\n",
    "\n",
    "    Args:\n",
    "        text (str): 将要被拆分的句子\n",
    "\n",
    "    Returns:\n",
    "        list: 拆分后的句子列表\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    sentences = []\n",
    "    slide_window_list = [i for i in range(0, len(words) - 1, step_size) if i + step_size < len(words) - 1]\n",
    "    for i in slide_window_list:\n",
    "        sentence = ' '.join(words[i:i+window_size])\n",
    "        sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "def tensorlize_texts_slideWindow(model, text, window_size, step_size):\n",
    "    \"\"\"\n",
    "    将长文本分块，然后对每块文本进行向量化，最后将这些向量平均。\n",
    "\n",
    "    Args:\n",
    "        model (CLIP): 使用的 CLIP 模型。\n",
    "        text (str): 输入的文本。\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: 文本特征向量。\n",
    "    \"\"\"\n",
    "\n",
    "    chunks = slide_window_tokenizer(text, window_size, step_size)\n",
    "    tensor_list = []\n",
    "    for chunk in chunks:\n",
    "        tokens = clip.tokenize([chunk]).cuda(device=device)\n",
    "        with torch.no_grad():\n",
    "            tensor_list.append(model.encode_text(tokens).float().cpu())\n",
    "    # 使用所有块的平均值作为文本的表示\n",
    "    avg_tensor = torch.mean(torch.stack(tensor_list), dim=0)\n",
    "    return avg_tensor.numpy().tolist()\n",
    "\n",
    "\n",
    "def tensorlize_valid_subsentence(model, text) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    截取有效的子句，然后求特征向量值\n",
    "\n",
    "    Args:\n",
    "        model (CLIP): 使用的 CLIP 模型。\n",
    "        text (str): 输入的文本。\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: 文本特征向量。\n",
    "    \"\"\"\n",
    "    text_tensor = None\n",
    "    # 标记为False时，表示该句子无法被模型处理，需要进行拆分\n",
    "    flag = False\n",
    "    words = text.split()\n",
    "    text_length = len(words)\n",
    "    while not flag:\n",
    "        try:\n",
    "            text_tensor = tensorlize_texts(model, text)\n",
    "            flag = True\n",
    "        except:\n",
    "            text_length -= 1\n",
    "            text = ' '.join(words[:text_length])\n",
    "    return text_tensor\n",
    "\n",
    "def legalize_text(text) -> str:\n",
    "    \"\"\"\n",
    "    截取有效长度的句子\n",
    "\n",
    "    Args:\n",
    "        text (str): 输入的文本。\n",
    "\n",
    "    Returns:\n",
    "        str: 截断之后的文本。\n",
    "    \"\"\"\n",
    "    # 标记为False时，表示该句子无法被模型处理，需要进行拆分\n",
    "    flag = False\n",
    "    words = text.split()\n",
    "    text_length = len(words)\n",
    "    while not flag:\n",
    "        try:\n",
    "            clip.tokenize(text)\n",
    "            flag = True\n",
    "        except:\n",
    "            text_length -= 1\n",
    "            text = ' '.join(words[:text_length])\n",
    "    return text\n",
    "\n",
    "def handle_long_texts(model, text_list) -> list:\n",
    "    \"\"\"\n",
    "    处理长文本，将长文本分块，然后对每块文本进行向量化，最后将这些向量平均。\n",
    "\n",
    "    Args:\n",
    "        model (CLIP): 使用的 CLIP 模型。\n",
    "        text_list (list): 输入的文本列表。\n",
    "        window_size (int): 窗口宽度\n",
    "        step_size (int): 窗口移动的步长\n",
    "\n",
    "    Returns:\n",
    "        list: 文本特征向量列表。\n",
    "    \"\"\"\n",
    "    # 先将长句子截断为有效短句子\n",
    "    legal_text_list = list(map(legalize_text, text_list))\n",
    "    text_features = tensorlize_texts(model, legal_text_list)\n",
    "    return text_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_base_path = Path(\"/data/sswang/data/mini100\")\n",
    "target_dataset_path = Path(\"/data/sswang/data/mini100_tensor_V2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理： CryptoPunks ...\n",
      "处理完成： CryptoPunks\n",
      "开始处理： BoredApeYachtClub ...\n",
      "处理完成： BoredApeYachtClub\n",
      "开始处理： MutantApeYachtClub ...\n",
      "处理完成： MutantApeYachtClub\n",
      "开始处理： Azuki ...\n",
      "处理完成： Azuki\n",
      "开始处理： CLONEX ...\n",
      "处理完成： CLONEX\n",
      "开始处理： Moonbirds ...\n",
      "处理完成： Moonbirds\n",
      "开始处理： Doodles ...\n",
      "处理完成： Doodles\n",
      "开始处理： BoredApeKennelClub ...\n",
      "处理完成： BoredApeKennelClub\n",
      "开始处理： Meebits ...\n",
      "处理完成： Meebits\n",
      "开始处理： PudgyPenguins ...\n",
      "处理完成： PudgyPenguins\n",
      "开始处理： Cool Cats ...\n",
      "处理完成： Cool Cats\n",
      "开始处理： Beanz ...\n",
      "处理完成： Beanz\n",
      "开始处理： MechMinds ...\n",
      "处理完成： MechMinds\n",
      "开始处理： World of Women ...\n",
      "处理完成： World of Women\n",
      "开始处理： CrypToadz ...\n",
      "处理完成： CrypToadz\n",
      "开始处理： 0N1 Force ...\n",
      "处理完成： 0N1 Force\n",
      "开始处理： mfers ...\n",
      "处理完成： mfers\n",
      "开始处理： Karafuru ...\n",
      "处理完成： Karafuru\n",
      "开始处理： HAPE PRIME ...\n",
      "处理完成： HAPE PRIME\n",
      "开始处理： MekaVerse ...\n",
      "处理完成： MekaVerse\n",
      "开始处理： projectPXN ...\n",
      "处理完成： projectPXN\n",
      "开始处理： FLUF ...\n",
      "处理完成： FLUF\n",
      "开始处理： Hashmasks ...\n",
      "处理完成： Hashmasks\n",
      "开始处理： Moonbirds Oddities ...\n",
      "处理完成： Moonbirds Oddities\n",
      "开始处理： Creature World ...\n",
      "处理完成： Creature World\n",
      "开始处理： 3Landers ...\n",
      "处理完成： 3Landers\n",
      "开始处理： Phanta Bear ...\n",
      "处理完成： Phanta Bear\n",
      "开始处理： CyberKongz VX ...\n",
      "处理完成： CyberKongz VX\n",
      "开始处理： Deadfellaz ...\n",
      "处理完成： Deadfellaz\n",
      "开始处理： KaijuKingz ...\n",
      "处理完成： KaijuKingz\n",
      "开始处理： VeeFriends Series 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sswang/anaconda3/envs/img_matching/lib/python3.9/site-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成： VeeFriends Series 2\n",
      "开始处理： Lazy Lions ...\n",
      "处理完成： Lazy Lions\n",
      "开始处理： World of Women Galaxy ...\n",
      "处理完成： World of Women Galaxy\n",
      "开始处理： ALIENFRENS ...\n",
      "处理完成： ALIENFRENS\n",
      "开始处理： Prime Ape Planet ...\n",
      "处理完成： Prime Ape Planet\n",
      "开始处理： The Doge Pound ...\n",
      "处理完成： The Doge Pound\n",
      "开始处理： Sappy Seals ...\n",
      "处理完成： Sappy Seals\n",
      "开始处理： CyberKongz ...\n",
      "处理完成： CyberKongz\n",
      "开始处理： DigiDaigaku ...\n",
      "处理完成： DigiDaigaku\n",
      "开始处理： CoolmansUniverse ...\n",
      "处理完成： CoolmansUniverse\n",
      "开始处理： VOX Series 1 ...\n",
      "处理完成： VOX Series 1\n",
      "开始处理： Capsule ...\n",
      "处理完成： Capsule\n",
      "开始处理： Murakami.Flowers ...\n",
      "处理完成： Murakami.Flowers\n",
      "开始处理： SupDucks ...\n",
      "处理完成： SupDucks\n",
      "开始处理： Valhalla ...\n",
      "处理完成： Valhalla\n",
      "开始处理： DEGEN TOONZ ...\n",
      "处理完成： DEGEN TOONZ\n",
      "开始处理： Lives of Asuna ...\n",
      "处理完成： Lives of Asuna\n",
      "开始处理： Nakamigos ...\n",
      "处理完成： Nakamigos\n",
      "开始处理： Sneaky Vampire Syndicate ...\n",
      "处理完成： Sneaky Vampire Syndicate\n",
      "开始处理： Killer GF ...\n",
      "处理完成： Killer GF\n",
      "开始处理： Adam Bomb Squad ...\n",
      "处理完成： Adam Bomb Squad\n",
      "开始处理： Impostors Genesis ...\n",
      "处理完成： Impostors Genesis\n",
      "开始处理： CryptoSkulls ...\n",
      "处理完成： CryptoSkulls\n",
      "开始处理： MURI ...\n",
      "处理完成： MURI\n",
      "开始处理： Weirdo Ghost Gang ...\n",
      "处理完成： Weirdo Ghost Gang\n",
      "开始处理： KILLABEARS ...\n",
      "处理完成： KILLABEARS\n",
      "开始处理： Acclimated​MoonCats ...\n",
      "处理完成： Acclimated​MoonCats\n",
      "开始处理： Milady ...\n",
      "处理完成： Milady\n",
      "开始处理： Chimpers ...\n",
      "处理完成： Chimpers\n",
      "开始处理： My Pet Hooligan ...\n",
      "处理完成： My Pet Hooligan\n",
      "开始处理： RumbleKongLeague ...\n",
      "处理完成： RumbleKongLeague\n",
      "开始处理： Jungle Freaks ...\n",
      "处理完成： Jungle Freaks\n",
      "开始处理： MetaHero ...\n",
      "处理完成： MetaHero\n",
      "开始处理： Bears Deluxe ...\n",
      "处理完成： Bears Deluxe\n",
      "开始处理： Lil Heroes ...\n",
      "处理完成： Lil Heroes\n",
      "开始处理： Quirkies ...\n",
      "处理完成： Quirkies\n",
      "开始处理： tubby cats ...\n",
      "处理完成： tubby cats\n",
      "开始处理： Galactic Apes ...\n",
      "处理完成： Galactic Apes\n",
      "开始处理： a KID called BEAST ...\n",
      "处理完成： a KID called BEAST\n",
      "开始处理： OnChainMonkey ...\n",
      "处理完成： OnChainMonkey\n",
      "开始处理： CryptoBatz by Ozzy Osbourne ...\n",
      "处理完成： CryptoBatz by Ozzy Osbourne\n",
      "开始处理： LilPudgys ...\n",
      "处理完成： LilPudgys\n",
      "开始处理： MutantCats ...\n",
      "处理完成： MutantCats\n",
      "开始处理： ForgottenRunesWizardsCult ...\n",
      "处理完成： ForgottenRunesWizardsCult\n",
      "开始处理： Boss Beauties ...\n",
      "处理完成： Boss Beauties\n",
      "开始处理： Keepers V2 ...\n",
      "处理完成： Keepers V2\n",
      "开始处理： Anonymice ...\n",
      "处理完成： Anonymice\n",
      "开始处理： Kiwami ...\n",
      "处理完成： Kiwami\n",
      "开始处理： HypeBears ...\n",
      "处理完成： HypeBears\n",
      "开始处理： Akutars ...\n",
      "处理完成： Akutars\n",
      "开始处理： GalaxyEggs ...\n",
      "处理完成： GalaxyEggs\n",
      "开始处理： SHIBOSHIS ...\n",
      "处理完成： SHIBOSHIS\n",
      "开始处理： CryptoMories ...\n",
      "处理完成： CryptoMories\n",
      "开始处理： Hero ...\n",
      "处理完成： Hero\n",
      "开始处理： Fighter ...\n",
      "处理完成： Fighter\n",
      "开始处理： C-01 Official Collection ...\n",
      "处理完成： C-01 Official Collection\n",
      "开始处理： Crypto Bull Society ...\n",
      "处理完成： Crypto Bull Society\n",
      "开始处理： Chain Runners ...\n",
      "处理完成： Chain Runners\n",
      "开始处理： KIA ...\n",
      "处理完成： KIA\n",
      "开始处理： MOAR by Joan Cornella ...\n",
      "处理完成： MOAR by Joan Cornella\n",
      "开始处理： OxyaOriginProject ...\n",
      "处理完成： OxyaOriginProject\n",
      "开始处理： Genuine Undead ...\n",
      "处理完成： Genuine Undead\n",
      "开始处理： The Humanoids ...\n",
      "处理完成： The Humanoids\n",
      "开始处理： The Heart Project ...\n",
      "处理完成： The Heart Project\n",
      "开始处理： inbetweeners ...\n",
      "处理完成： inbetweeners\n",
      "开始处理： Sevens Token ...\n",
      "处理完成： Sevens Token\n",
      "开始处理： Kanpai Pandas ...\n",
      "处理完成： Kanpai Pandas\n",
      "开始处理： Owls ...\n",
      "处理完成： Owls\n",
      "开始处理： WonderPals ...\n",
      "处理完成： WonderPals\n",
      "开始处理： Groupies ...\n",
      "处理完成： Groupies\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import copy\n",
    "\n",
    "NFT_list_dict = load_json(dataset_base_path.joinpath(\"NFT_list.json\"))\n",
    "\n",
    "collection_list_copy = copy.deepcopy(NFT_list_dict[\"collection_list_copy\"])\n",
    "\n",
    "for key, value in collection_list_copy.items():\n",
    "    NFT_collection_path = dataset_base_path.joinpath(value)\n",
    "    print(\"开始处理：\", NFT_collection_path.name, \"...\")\n",
    "    check_dir(target_dataset_path.joinpath(NFT_collection_path.name))\n",
    "\n",
    "    NFT_tensor_data = {}\n",
    "    img_path_list = list(NFT_collection_path.joinpath(\"img\").iterdir())\n",
    "    # 提取图片名称\n",
    "    img_name_list = [img_path.stem for img_path in img_path_list]\n",
    "\n",
    "    # 提取图片特征向量\n",
    "    image_features_CPU = tensorlize_imgs(model, img_path_list)\n",
    "\n",
    "    # 提取文本特征向量\n",
    "    des_tensor = []\n",
    "    des_query_dict = load_json(NFT_collection_path.joinpath(\"description.json\"))\n",
    "\n",
    "    for img_name in img_name_list:\n",
    "        # 去掉 description 中的序号（也就是1. 2. 3.）\n",
    "        des_list = [re.sub(r'^\\d+\\. ', '', des) for des in des_query_dict[img_name]]\n",
    "        des_features = None\n",
    "        # 判断描述的长度有没有超过77\n",
    "        if is_str_Length_valid(des_list) == False:\n",
    "            # 如果超过77，就使用特殊处理方式\n",
    "            des_features = handle_long_texts(model, des_list)\n",
    "        else:\n",
    "            des_features = tensorlize_texts(model, des_list)\n",
    "        des_tensor.append(des_features)\n",
    "\n",
    "    NFT_tensor_data[\"img_name_list\"] = img_name_list\n",
    "    NFT_tensor_data[\"image_features\"] = image_features_CPU.numpy().tolist()\n",
    "    NFT_tensor_data[\"des_tensors\"] = des_tensor\n",
    "    save_json(target_dataset_path.joinpath(NFT_collection_path.name, \"NFT_tensor_data.json\"), NFT_tensor_data)\n",
    "    print(\"处理完成：\", NFT_collection_path.name)\n",
    "    \n",
    "    # 将已经处理完成的项目从列表中删除\n",
    "    del NFT_list_dict[\"collection_list_copy\"][key]\n",
    "    # 将处理完成的项目列表保存到json文件中\n",
    "    save_json(dataset_base_path.joinpath(\"NFT_list.json\"), NFT_list_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算图像特征和描述特征的余弦相似度\n",
    "image_features = load_img_tensor(device, target_dataset_path.joinpath(\"Prime Ape Planet\", \"NFT_tensor_data.json\"))\n",
    "des_features = load_des_tensor(device, target_dataset_path.joinpath(\"Prime Ape Planet\", \"NFT_tensor_data.json\"))\n",
    "des_features1, des_features2, des_feature3 = des_features\n",
    "top_probs, top_labels = calculate_cosine_similarity_topk(image_features, des_features1, 10)\n",
    "print(top_probs.shape)\n",
    "print(top_probs)\n",
    "print(top_labels.shape)\n",
    "print(top_labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collection 内部测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 768])\n",
      "torch.Size([3, 100, 768])\n"
     ]
    }
   ],
   "source": [
    "# 加载特征向量\n",
    "collection_path_list = target_dataset_path.iterdir()\n",
    "for collection in collection_path_list:\n",
    "    # 找到路径下的tensor文件\n",
    "    tensor_path = collection.joinpath(\"NFT_tensor_data.json\")\n",
    "    # image_features = load_img_tensor(device, tensor_path)\n",
    "    des_features = load_des_tensor(device, tensor_path)\n",
    "    # print(image_features.shape)\n",
    "    # print(des_features.shape)\n",
    "    # for des_feature in des_features:\n",
    "    #     top_probs, top_labels = calculate_cosine_similarity_topk(image_features, des_feature, 10)\n",
    "    #     print(top_probs.shape)\n",
    "    #     print(top_probs)\n",
    "    #     print(top_labels.shape)\n",
    "    #     print(top_labels)\n",
    "\n",
    "    break\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NFT_search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
