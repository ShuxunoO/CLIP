{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 427,944,193\n",
      "Input resolution: 336\n",
      "Context length: 77\n",
      "Vocab size: 49408\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from pkg_resources import packaging\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from pathlib import Path\n",
    "import clip.clip as clip\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model, preprocess = clip.load(\"ViT-B/32\")\n",
    "model, preprocess = clip.load(name=\"/datassd2/sswang/NFT_Search/CLIP/models/ViT-L-14-336px.pt\", device=device)\n",
    "# 将模型加载到GPU中并切换到评估模式\n",
    "model.eval()\n",
    "input_resolution = model.visual.input_resolution\n",
    "context_length = model.context_length\n",
    "vocab_size = model.vocab_size\n",
    "\n",
    "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
    "print(\"Input resolution:\", input_resolution)\n",
    "print(\"Context length:\", context_length)\n",
    "print(\"Vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def slide_window_tokenizer(text, window_size, step_size) -> list:\n",
    "    \"\"\"\n",
    "    为了处理长度超过77的句子，这里设计滑动窗口分词\n",
    "\n",
    "    Args:\n",
    "        text (str): 将要被拆分的句子\n",
    "\n",
    "    Returns:\n",
    "        list: 拆分后的句子列表\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    sentences = []\n",
    "    slide_window_list = [i for i in range(0, len(words) - 1, step_size) if i + step_size < len(words) - 1]\n",
    "    for i in slide_window_list:\n",
    "        sentence = ' '.join(words[i:i+window_size])\n",
    "        sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "def split_text(text, para_num) -> list:\n",
    "    \"\"\"\n",
    "    将长句子拆分成指定段数的短句子\n",
    "\n",
    "    Args:\n",
    "        text (str): 将要被拆分的文本\n",
    "\n",
    "    Returns:\n",
    "        list: 拆分后的句子列表\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    words = text.split()\n",
    "    step_size = len(words) // para_num\n",
    "    for i in range(0, len(words) - 1, step_size):\n",
    "        sentence = ' '.join(words[i:i+step_size])\n",
    "        sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "def tensorlize_texts(model, text_tokens_list) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    使用模型提取文本特征，返回文本特征向量列表\n",
    "\n",
    "    Args:\n",
    "        model (CLIP): 使用的 CLIP 模型。\n",
    "        text_tokens_list (str): 输入的文本列表\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: 文本特征向量列表\n",
    "    \"\"\"\n",
    "    text_tokens = clip.tokenize(text_tokens_list, context_length = 77).cuda( device=device)\n",
    "    with torch.no_grad():\n",
    "        text_features = model.encode_text(text_tokens).float().cpu()\n",
    "        return text_features\n",
    "    \n",
    "\n",
    "def tensorlize_texts_slideWindow(model, text, window_size, step_size):\n",
    "    \"\"\"\n",
    "    将长文本分块，然后对每块文本进行向量化，最后将这些向量平均。\n",
    "\n",
    "    Args:\n",
    "        model (CLIP): 使用的 CLIP 模型。\n",
    "        text (str): 输入的文本。\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: 文本特征向量。\n",
    "    \"\"\"\n",
    "\n",
    "    chunks = slide_window_tokenizer(text, window_size, step_size)\n",
    "    tensor_list = []\n",
    "    for chunk in chunks:\n",
    "        tokens = clip.tokenize([chunk]).cuda(device=device)\n",
    "        with torch.no_grad():\n",
    "            tensor_list.append(model.encode_text(tokens).float().cpu())\n",
    "    # 使用所有块的平均值作为文本的表示\n",
    "    avg_tensor = torch.mean(torch.stack(tensor_list), dim=0)\n",
    "    return avg_tensor\n",
    "\n",
    "\n",
    "def tensorlize_texts_chunked(model, text, para_num):\n",
    "    \"\"\"\n",
    "    将长文本分块，然后对每块文本进行向量化，最后将这些向量平均。\n",
    "\n",
    "    Args:\n",
    "        model (CLIP): 使用的 CLIP 模型。\n",
    "        text (str): 输入的文本。\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: 文本特征向量。\n",
    "    \"\"\"\n",
    "\n",
    "    chunks = split_text(text, para_num)\n",
    "    tensor_list = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        tokens = clip.tokenize([chunk]).cuda(device=device)\n",
    "        with torch.no_grad():\n",
    "            tensor_list.append(model.encode_text(tokens).float().cpu())\n",
    "\n",
    "    #使用所有块的平均值作为文本的表示\n",
    "    avg_tensor = torch.mean(torch.stack(tensor_list), dim=0)\n",
    "    return avg_tensor\n",
    "\n",
    "\n",
    "def calculate_cosine_similarity(tensor1, tensor2):\n",
    "    \"\"\"\n",
    "    计算两个张量之间的余弦相似度\n",
    "\n",
    "    Args:\n",
    "        tensor1 (torch.Tensor): 第一个张量\n",
    "        tensor2 (torch.Tensor): 第二个张量\n",
    "\n",
    "    Returns:\n",
    "        float: 余弦相似度\n",
    "    \"\"\"\n",
    "    tensor1 /= tensor1.norm(dim=-1, keepdim=True)\n",
    "    tensor2 /= tensor2.norm(dim=-1, keepdim=True)\n",
    "    similarity = tensor1.cpu().numpy() @ tensor2.cpu().numpy().T\n",
    "    return similarity.item()\n",
    "\n",
    "\n",
    "def tensorlize_valid_subsentence(model, text):\n",
    "    text_tensor = None\n",
    "    # 标记为False时，表示该句子无法被模型处理，需要进行拆分\n",
    "    flag = False\n",
    "    words = text.split()\n",
    "    text_length = len(words)\n",
    "    while not flag:\n",
    "        try:\n",
    "            text_tensor = tensorlize_texts(model, text)\n",
    "            flag = True\n",
    "        except:\n",
    "            text_length -= 1\n",
    "            text = ' '.join(words[:text_length])\n",
    "    return text_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.2388e-02,  5.1953e-01, -6.0394e-02, -4.6143e-02,  3.8135e-01,\n",
      "          1.3843e-01,  1.7908e-01,  9.1171e-03,  4.7949e-01, -4.5630e-01,\n",
      "          1.8396e-01, -6.1426e-01, -8.7219e-02,  8.6621e-01, -8.5596e-01,\n",
      "         -4.9658e-01,  6.4990e-01, -1.2109e-01,  3.0396e-01, -6.9971e-01,\n",
      "          9.5654e-01, -1.0101e-02, -3.4473e-01, -7.3181e-02,  1.0187e-01,\n",
      "         -3.7256e-01, -5.1172e-01, -3.1543e-01,  1.6309e-01, -9.9487e-02,\n",
      "         -1.6418e-01, -1.7651e-01, -6.4648e-01,  2.1774e-02, -2.5439e-01,\n",
      "          6.1523e-01,  5.5273e-01,  4.2938e-02, -4.5142e-01, -3.5010e-01,\n",
      "          4.0771e-01,  5.2307e-02, -1.2421e-01, -2.5488e-01,  1.9836e-01,\n",
      "          8.8074e-02,  2.8833e-01, -7.6477e-02,  1.0168e-01, -5.0439e-01,\n",
      "         -5.1727e-02,  9.5596e-03,  1.0925e-01,  4.8901e-01,  3.0273e-01,\n",
      "          3.1738e-02,  5.8740e-01, -3.9551e-01,  1.3171e-01, -1.8152e-01,\n",
      "          3.9697e-01, -2.7267e-02,  9.0576e-02,  8.3191e-02, -6.8665e-02,\n",
      "          2.5171e-01,  4.6875e-01, -5.4297e-01,  1.3147e-01,  1.6492e-01,\n",
      "         -1.3916e-02, -1.9495e-01,  4.3549e-02,  3.9502e-01, -3.0322e-01,\n",
      "         -1.0364e-01,  3.4692e-01, -3.2324e-01,  3.2910e-01, -3.3008e-01,\n",
      "          4.6069e-01,  2.8711e-01,  2.2058e-01, -4.3152e-02, -1.4709e-01,\n",
      "          2.7539e-01, -4.8291e-01, -2.2949e-01, -1.7786e-01,  2.3218e-01,\n",
      "         -3.0151e-01,  1.6980e-01,  8.4656e-02,  4.9561e-02,  3.0835e-01,\n",
      "         -4.7974e-01,  5.9277e-01,  1.9702e-01,  5.5957e-01,  1.5930e-01,\n",
      "         -6.6650e-01,  4.1504e-01,  7.4280e-02,  1.0788e-02,  2.8979e-01,\n",
      "         -3.7842e-01, -3.2520e-01, -1.8665e-01,  3.9600e-01,  2.2974e-01,\n",
      "          1.3818e-01, -9.4336e-01,  1.1328e-01,  1.9946e-01, -2.5073e-01,\n",
      "         -5.2100e-01,  2.1033e-01,  4.6883e-03,  3.1299e-01,  2.3682e-01,\n",
      "         -5.3076e-01, -5.7812e-01,  8.5107e-01, -8.3252e-02,  3.6279e-01,\n",
      "         -1.5271e-01, -6.4270e-02,  1.6678e-02, -1.6711e-01,  1.4307e-01,\n",
      "         -3.0005e-01, -8.6621e-01,  2.3022e-01, -7.7100e-01,  6.1426e-01,\n",
      "         -8.4473e-01, -2.6538e-01,  5.0977e-01,  9.5020e-01, -2.5122e-01,\n",
      "          4.9023e-01, -8.2422e-01, -1.5637e-01,  4.2554e-01, -2.7515e-01,\n",
      "         -3.3105e-01, -1.2732e-01, -1.3098e-01,  3.0176e-01, -1.4160e-01,\n",
      "         -2.2314e-01,  2.1210e-02,  5.9912e-01, -5.6885e-02,  1.7139e-01,\n",
      "          2.3901e-01,  3.0542e-01,  6.8799e-01, -4.0100e-02, -7.8857e-02,\n",
      "         -5.4150e-01,  1.3037e-01,  1.6357e-01, -1.5344e-01,  1.4209e-01,\n",
      "          6.1719e-01,  1.6479e-01,  4.2261e-01,  7.3730e-02, -1.0166e+00,\n",
      "          4.3396e-02, -1.9067e-01, -1.3684e-01,  5.1270e-01,  1.7810e-01,\n",
      "          4.1260e-01, -2.8397e-02, -9.0234e-01,  3.0200e-01, -1.5527e-01,\n",
      "          6.9824e-01, -9.4788e-02, -5.3271e-01, -1.7786e-01,  6.1523e-01,\n",
      "         -7.5439e-01,  1.0718e-01, -3.9795e-01,  2.4731e-01, -5.2148e-01,\n",
      "         -6.6162e-01,  4.7913e-02,  1.5465e-02, -2.1643e-01, -2.2241e-01,\n",
      "         -7.6855e-01, -5.3857e-01,  7.5098e-01, -3.6450e-01, -6.9824e-01,\n",
      "         -1.0785e-01, -2.4414e-01,  3.3398e-01,  4.2871e-01,  7.4280e-02,\n",
      "          8.2520e-02, -5.7770e-02, -8.5449e-02, -9.4788e-02, -1.3574e-01,\n",
      "          5.2917e-02, -2.6465e-01, -6.9727e-01, -1.5320e-01, -6.3916e-01,\n",
      "         -2.0599e-02, -1.9861e-01,  4.9292e-01,  1.9507e-01,  2.6538e-01,\n",
      "         -1.7468e-01,  1.1676e-01,  2.8760e-01, -1.7249e-01,  7.8418e-01,\n",
      "         -6.4502e-01, -3.6450e-01, -5.5084e-02,  5.7617e-01, -7.1582e-01,\n",
      "          5.6494e-01,  2.5269e-01, -5.6152e-01, -2.6099e-01,  8.6670e-01,\n",
      "         -2.1729e-02, -1.0732e+00, -3.7158e-01,  4.2627e-01, -2.1777e-01,\n",
      "          1.1945e-01, -2.0691e-01,  2.6025e-01,  3.8574e-01, -1.5210e-01,\n",
      "          5.6592e-01, -7.3096e-01,  1.5808e-02, -4.5593e-02,  1.3525e-01,\n",
      "          3.2129e-01,  1.0791e+00,  7.5244e-01, -5.8691e-01, -1.7188e-01,\n",
      "          2.0325e-01,  8.2666e-01, -2.0520e-01,  7.2876e-02, -6.1035e-01,\n",
      "         -2.2522e-01,  7.5928e-01, -2.5049e-01,  9.2920e-01,  4.7583e-01,\n",
      "          1.8848e-01,  4.4287e-01, -4.7314e-01,  4.5471e-02, -1.2463e-01,\n",
      "          8.5999e-02, -4.1064e-01,  8.8574e-01, -1.5771e-01,  6.4087e-02,\n",
      "         -7.7576e-02,  3.7964e-01,  2.1484e-01, -5.8740e-01, -1.5991e-01,\n",
      "          2.7710e-01, -4.1565e-02, -3.0469e-01,  4.0436e-02,  2.1362e-01,\n",
      "          2.1790e-01,  8.4839e-02,  5.2277e-02, -5.1807e-01, -4.5093e-01,\n",
      "         -4.2896e-01, -1.6467e-01,  6.2354e-01,  3.5571e-01,  3.8605e-02,\n",
      "         -2.5513e-01,  2.5539e-03, -3.9185e-01,  1.9360e-01,  5.3369e-01,\n",
      "          1.0992e-01, -2.9663e-01, -1.5088e-01, -5.3760e-01,  2.1716e-01,\n",
      "         -3.0273e-01,  3.6499e-01, -4.5410e-01,  1.0895e-02, -5.6885e-01,\n",
      "         -7.3853e-02,  6.5479e-01, -5.6348e-01, -2.9126e-01,  5.6348e-01,\n",
      "          8.9661e-02, -2.8477e+00, -3.4766e-01,  2.7054e-02, -5.7526e-02,\n",
      "         -2.1875e-01, -5.9717e-01,  6.8359e-01, -1.2245e-02, -1.2842e-01,\n",
      "          1.4636e-01, -6.2158e-01,  9.8938e-02,  7.7515e-02,  1.0796e-02,\n",
      "         -4.1675e-01,  6.2805e-02, -5.7434e-02, -1.2524e-01, -5.4590e-01,\n",
      "         -2.5635e-01,  1.4111e-01, -5.5469e-01, -5.7910e-01,  5.5469e-01,\n",
      "         -1.0376e-01,  3.3569e-01,  5.0244e-01, -4.1992e-01,  2.3636e-02,\n",
      "          3.2861e-01,  1.2250e-01,  1.4050e-01, -8.6182e-02, -4.4531e-01,\n",
      "          3.3545e-01,  1.2030e-01, -5.9131e-01, -6.7810e-02, -3.5474e-01,\n",
      "          3.6011e-01, -4.5624e-03, -2.3682e-01, -1.6748e-01,  3.8843e-01,\n",
      "          6.6895e-02, -2.8247e-01,  1.3562e-01,  2.7124e-01, -9.7595e-02,\n",
      "         -9.2468e-02,  6.1035e-01,  2.4731e-01, -6.8298e-02,  1.1145e-01,\n",
      "         -2.8906e-01, -6.4453e-02, -1.4050e-01,  5.2460e-02, -3.4644e-01,\n",
      "         -6.0449e-01,  2.9541e-01,  4.7974e-01,  1.8054e-01,  4.9988e-02,\n",
      "          1.0376e-01, -2.1680e-01, -2.6270e-01,  3.7750e-02, -1.1877e-01,\n",
      "         -3.2397e-01, -2.1378e-02, -1.6235e-01, -9.4849e-02,  3.8965e-01,\n",
      "         -3.4326e-01,  4.2773e-01, -3.5791e-01, -9.9976e-02,  3.0566e-01,\n",
      "         -5.1270e-02,  9.7803e-01, -1.0419e-01,  4.0308e-01,  2.1252e-01,\n",
      "          1.1865e-01,  4.3457e-01,  8.2178e-01, -1.0687e-01, -6.4648e-01,\n",
      "          2.1460e-01,  5.0415e-02, -3.4155e-01, -3.4766e-01,  4.1943e-01,\n",
      "         -4.3652e-01, -2.4438e-01,  2.1082e-01, -6.0889e-01,  5.0635e-01,\n",
      "         -6.1816e-01, -1.5137e-01, -1.0620e-01,  4.3628e-01,  2.0288e-01,\n",
      "         -5.8936e-01,  6.9519e-02,  1.0992e-01,  3.8916e-01, -6.5918e-01,\n",
      "          1.0999e-01,  6.5137e-01,  4.7119e-01,  5.7959e-01,  2.3145e-01,\n",
      "          2.2656e-01,  2.3804e-01,  3.0640e-01, -1.6357e-01,  8.3923e-02,\n",
      "          7.3730e-01,  5.0928e-01, -6.5039e-01, -2.0117e-01,  5.6915e-02,\n",
      "          2.5547e+00, -3.9722e-01, -4.1577e-01, -1.7383e-01, -3.3838e-01,\n",
      "         -8.8623e-02, -9.7473e-02,  5.5029e-01,  9.7070e-01, -5.5206e-02,\n",
      "         -4.0405e-01, -3.3789e-01, -1.6675e-01,  5.5634e-02, -1.2231e-01,\n",
      "          1.1104e+00, -2.5830e-01, -7.6721e-02, -5.1562e-01, -3.2617e-01,\n",
      "         -8.3618e-03,  7.0654e-01,  3.1567e-01,  2.6001e-01, -1.3220e-01,\n",
      "          2.8540e-01,  3.6560e-02,  3.5083e-01, -5.1147e-02,  8.4619e-01,\n",
      "          1.4551e-01, -6.0498e-01, -2.0966e-02, -2.0349e-01, -5.1270e-01,\n",
      "          6.8207e-03,  4.7266e-01, -2.4854e-01, -5.8887e-01, -2.1436e-01,\n",
      "         -7.2803e-01, -4.0454e-01, -2.4158e-01, -1.6858e-01, -8.2666e-01,\n",
      "         -1.9116e-01,  3.7915e-01, -8.4900e-02,  1.4136e-01, -3.7671e-01,\n",
      "          3.1104e-01,  1.3306e-01, -6.6357e-01,  1.5759e-01, -5.6201e-01,\n",
      "         -1.8701e-01,  3.1738e-01, -3.3521e-01, -9.7266e-01,  7.6050e-02,\n",
      "          3.3447e-01, -1.0605e+00, -1.5320e-01,  7.4121e-01, -3.4961e-01,\n",
      "         -4.7852e-01, -3.8013e-01,  2.0068e-01, -4.7363e-01,  6.0059e-01,\n",
      "          7.6611e-01,  3.1641e-01,  7.5391e-01, -1.0510e-01,  3.0103e-01,\n",
      "          1.4478e-01,  3.5181e-01, -7.9980e-01, -1.3086e-01,  2.3865e-01,\n",
      "         -1.0034e-01,  4.4727e-01, -1.4331e-01,  2.9272e-01,  8.9404e-01,\n",
      "         -1.5930e-01,  4.2798e-01,  4.6875e-01, -4.0723e-01, -2.1729e-01,\n",
      "         -2.4365e-01, -1.5649e-01,  2.5220e-01,  8.4167e-02,  6.7334e-01,\n",
      "         -2.5220e-01,  2.3877e-01, -3.4009e-01, -3.6548e-01, -1.2611e-02,\n",
      "          2.9346e-01,  9.6729e-01,  2.9761e-01, -2.3251e-03,  1.0414e-02,\n",
      "         -5.1953e-01,  9.6741e-02,  5.0439e-01,  1.3867e-01,  2.3956e-02,\n",
      "          7.5928e-01,  6.0352e-01, -3.7061e-01, -3.3716e-01,  6.2988e-01,\n",
      "         -3.0225e-01, -3.1128e-01,  2.1835e-02, -4.2773e-01,  2.6880e-01,\n",
      "          1.1162e+00,  5.7178e-01, -3.9429e-01, -2.0459e-01,  5.7324e-01,\n",
      "          2.9395e-01, -6.8506e-01,  5.5664e-01, -1.7688e-01,  1.7639e-01,\n",
      "          5.4785e-01,  9.6375e-02,  2.0337e-01, -4.7144e-01, -1.2915e-01,\n",
      "         -8.3496e-01,  2.1863e-01,  2.5977e-01,  2.1216e-01,  2.9053e-01,\n",
      "          5.0488e-01, -3.6499e-01,  8.5693e-02,  4.7241e-01,  1.3110e-01,\n",
      "         -7.4121e-01,  4.8340e-01, -6.7871e-02,  5.9131e-01,  1.4624e-01,\n",
      "          2.9980e-01, -6.0840e-01, -2.0691e-01, -2.8320e-01,  2.9517e-01,\n",
      "          3.6719e-01,  1.8823e-01, -6.5381e-01,  7.5537e-01,  1.2573e-01,\n",
      "         -3.8770e-01, -1.9153e-01,  2.2974e-01,  8.4033e-01, -2.9028e-01,\n",
      "         -2.1729e-01, -1.7029e-01,  7.1240e-01, -2.0178e-01,  1.9348e-01,\n",
      "         -1.6821e-01, -2.2534e-01, -5.0098e-01, -1.5320e-01, -3.7988e-01,\n",
      "          4.9854e-01,  4.4824e-01,  1.7896e-01,  6.7139e-02, -7.8735e-02,\n",
      "         -6.7139e-01, -1.6797e-01,  5.1178e-02, -2.5986e-02, -1.9507e-01,\n",
      "          4.9170e-01, -8.5352e-01,  9.7595e-02, -3.3203e-01, -3.4546e-02,\n",
      "         -3.0566e-01,  9.9976e-02, -7.5977e-01, -3.2593e-01,  7.4524e-02,\n",
      "         -5.6250e-01, -3.3252e-01, -6.9824e-02,  6.4844e-01, -7.8760e-01,\n",
      "         -9.5520e-02, -1.5556e-02,  3.2715e-01,  1.1902e-01,  6.2158e-01,\n",
      "          8.0664e-01, -2.0569e-01,  5.7812e-01,  5.5518e-01, -5.2197e-01,\n",
      "          4.1168e-02, -9.5886e-02, -6.1963e-01, -2.9590e-01, -2.8076e-01,\n",
      "          3.0054e-01, -8.1909e-02, -1.0638e-01,  5.9424e-01,  3.9764e-02,\n",
      "          7.8857e-02, -1.8213e-01,  3.1714e-01, -4.1382e-01, -2.8613e-01,\n",
      "         -7.6514e-01, -5.2100e-01,  3.2959e-01, -9.7107e-02,  9.6729e-01,\n",
      "         -2.4011e-01,  4.8126e-02, -3.9917e-01,  2.3914e-01, -1.5820e-01,\n",
      "         -3.4229e-01,  2.5488e-01, -1.8738e-01, -1.0046e-01,  1.1316e-01,\n",
      "         -1.5234e-01, -2.6294e-01, -1.7993e-01,  3.9502e-01, -1.7932e-01,\n",
      "          3.8599e-01,  4.5923e-01,  2.1704e-01, -5.3027e-01,  1.5564e-01,\n",
      "          2.6514e-01,  2.8296e-01,  2.3999e-01,  2.6245e-01, -2.3608e-01,\n",
      "         -3.7964e-01,  1.8433e-01,  8.5352e-01, -5.4102e-01, -3.6353e-01,\n",
      "         -4.2944e-01, -9.6094e-01, -5.7922e-02, -7.1240e-01,  3.9819e-01,\n",
      "          4.1321e-02, -2.7686e-01, -1.5979e-01,  6.5674e-01, -2.5610e-01,\n",
      "         -4.8438e-01,  6.2305e-01, -6.2256e-01,  4.8560e-01,  4.5166e-01,\n",
      "          3.9990e-01, -1.5845e-01,  1.4502e-01, -2.8076e-01, -6.1475e-01,\n",
      "          3.4760e-02, -2.2021e-01, -6.5491e-02, -8.4521e-01,  2.5732e-01,\n",
      "         -1.2354e-01,  5.8984e-01,  3.4851e-02, -9.5703e-01,  6.0400e-01,\n",
      "          1.3940e-01,  3.7183e-01, -6.3538e-02, -7.3096e-01,  4.6436e-01,\n",
      "          5.4980e-01,  5.4150e-01,  3.4375e-01,  4.8920e-02,  4.1626e-01,\n",
      "          3.8208e-01,  3.5303e-01, -2.1497e-01, -1.8921e-01, -1.7932e-01,\n",
      "         -7.8906e-01,  8.1445e-01,  2.2571e-01, -3.2690e-01, -3.3295e-02,\n",
      "         -3.8623e-01, -1.2372e-01,  1.0468e-01,  2.5757e-01,  4.6362e-01,\n",
      "         -5.3857e-01,  2.2192e-01, -2.3535e-01, -1.3879e-01, -2.4023e-01,\n",
      "          1.4294e-01, -2.9785e-01,  5.6055e-01,  3.1763e-01, -1.7334e-01,\n",
      "         -3.1708e-02,  1.0571e-01,  2.5684e-01]])\n"
     ]
    }
   ],
   "source": [
    "str1 = \"A picture of a triangular shape with a background of 2, covered in fur with a value of 6, without any earrings, wearing a hat with a value of 6, with eyes having a value of 14, not wearing any clothes, and without a mouth.A picture of a triangular shape with a background of 2, covered in fur with a value of 6, without any earrings, wearing a hat with a value of 6, with eyes having a value of 14, not wearing any clothes, and without a mouth.\"\n",
    "print(tensorlize_valid_subsentence(model, str1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "45\n",
      "45\n",
      "=========================================\n",
      "46\n",
      "50\n",
      "54\n",
      "=========================================\n",
      "38\n",
      "38\n",
      "43\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "list1 = [\n",
    "        \"A picture of a triangular shape with a background of 2, covered in fur with a value of 6, without any earrings, wearing a hat with a value of 6, with eyes having a value of 14, not wearing any clothes, and without a mouth.\",\n",
    "        \"A picture of a rectangular shape with a background of 2, covered in fur with a value of 6, without any earrings, wearing a hat with a value of 6, with eyes having a value of 14, not wearing any clothes, and without a mouth.\",\n",
    "        \"A picture of a circular shape with a background of 2, covered in fur with a value of 6, without any earrings, wearing a hat with a value of 6, with eyes having a value of 14, not wearing any clothes, and without a mouth.\"\n",
    "    ]\n",
    "\n",
    "list2 = [\n",
    "        \"A picture of a Prime Ape on their planet wearing a silver sweater, with green eyes and a rainbow-colored skin, showing an excited expression. They have white teeth and a leather jacket, and are wearing 3D glasses while holding a slice of pizza in their mouth.\",\n",
    "        \"A snapshot of Prime Ape Planet featuring a rainbow-colored creature with green eyes, wearing a silver sweater and a leather jacket. They are grinning widely, showing off their white teeth, and holding a slice of pizza in their mouth. The 3D glasses on their face add to their excited expression.\",\n",
    "        \"A visual of Prime Ape Planet showcasing a creature with a rainbow-colored skin, wearing a silver sweater and a leather jacket. They have green eyes and a wide grin, revealing their white teeth, and are holding a slice of pizza in their mouth. The 3D glasses on their face add to their excited expression.\"\n",
    "    ]\n",
    "\n",
    "list3 = [\n",
    "        \"A picture of a 3D model wearing a turtleneck white shirt, a king silver necklace, and a propeller hat. The skin of the model is lava, and it has a half bull ring nose and cyclops silver glasses.\",\n",
    "        \"A 3D model is depicted in the picture, wearing a turtleneck white shirt, a king silver necklace, and a propeller hat. The model's skin is lava, and it has a half bull ring nose and cyclops silver glasses.\",\n",
    "        \"The picture shows a 3D model wearing a turtleneck white shirt, a king silver necklace, and a propeller hat. The model's skin is lava, and it has a half bull ring nose and cyclops silver glasses, making it a unique and striking image.\"\n",
    "    ]\n",
    "\n",
    "text_list = [list1, list2, list3]\n",
    "for texts in text_list:\n",
    "    for text in texts:\n",
    "        print(len(text.split()))\n",
    "    print(\"=========================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "57\n",
      "54\n",
      "\n",
      "====================\n",
      "\n",
      "54\n",
      "55\n",
      "54\n",
      "\n",
      "====================\n",
      "\n",
      "57\n",
      "56\n",
      "56\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list1 = [\n",
    "        \"A picture of a triangular shape with a background of 2, covered in fur with a hat with a value of 6, with eyes having a value of 14, not wearing any with eyes having a value of 14, not wearing, and without a mouth A picture of a triangular shape with a covered in fur with a value of 6\",\n",
    "        \"A picture of a rectangular shape with a background of 2, covered in fur with a value of 6, without any earrings, wearing a hat with a value of 6, with eyes having a value of 14, not wearing any clothes, and without a mouth not wearing any clothes, and without a mouth and without a mouth.\",\n",
    "        \"A picture of a circular shape with a background of 2, covered in fur with a value of 6, without any earrings, wearing a hat  with eyes having a value of 14, not wearing any clothes, and without a mouth eyes having a value of 14, not wearing any clothes, and without a mouth.\"\n",
    "    ]\n",
    "\n",
    "list2 = [\n",
    "        \"A picture of a Prime Ape on their planet wearing a silver sweater, with green eyes and a rainbow-colored skin, showing an excited expression. They have white teeth and a leather jacket, and are wearing 3D glasses while holding a slice of pizza in their mouth holding a slice of pizza in their mouth.\",\n",
    "        \"A snapshot of Prime Ape Planet featuring a rainbow-colored creature with green eyes, wearing a silver sweater and a leather jacket. They are grinning widely, showing off their white teeth, and holding a slice of pizza in their mouth. The 3D glasses on their face add to their excited expression add to their excited expression.\",\n",
    "        \"A visual of Prime Ape Planet showcasing a creature with a rainbow-colored skin, wearing a silver sweater and a leather jacket. They have green eyes and a wide grin, revealing their white teeth, and are holding a slice of pizza in their mouth. The 3D glasses on their face add to their excited expression.\"\n",
    "    ]\n",
    "\n",
    "list3 = [\n",
    "        \"A picture of a 3D model wearing a turtleneck white shirt, a king silver necklace, and a propeller hat. The skin of the model is lava, and it has a half bull ring nose and cyclops silver glasses The skin of the model is lava, and it has a half bull ring nose and cyclops silver glasses\",\n",
    "        \"A 3D model is depicted in the picture, wearing a turtleneck white shirt, a king silver necklace, and a propeller hat. The model's skin is lava, and it has a half bull ring nose and cyclops silver glasses and it has a half bull ring nose and cyclops silver glasses ring nose and cyclops silver glasses.\",\n",
    "        \"The picture shows a 3D model wearing a turtleneck white shirt, a king silver necklace, and a propeller hat. The model's skin is lava, and it has a half bull ring nose and cyclops silver glasses, making it a unique and striking image ring nose and cyclops silver glasses, making it a unique and striking image.\"\n",
    "    ]\n",
    "\n",
    "text_list = [list1, list2, list3]\n",
    "for texts in text_list:\n",
    "    for text in texts:\n",
    "        print(len(text.split()))\n",
    "    print(\"\\n====================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000001192092896\n",
      "1.0000001192092896\n",
      "1.0000001192092896\n",
      "\n",
      "====================\n",
      "\n",
      "1.0\n",
      "1.0000001192092896\n",
      "0.9999998807907104\n",
      "\n",
      "====================\n",
      "\n",
      "1.0000001192092896\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 直接舍弃后面部分的内容\n",
    "for text in text_list:\n",
    "    full_text_tensor = tensorlize_texts(model, text)\n",
    "    text_tensor = []  # 3个tensor的列表\n",
    "\n",
    "    for full_text_tensor_item1, full_text_tensor_item2 in zip(full_text_tensor, full_text_tensor):\n",
    "        print(calculate_cosine_similarity(full_text_tensor_item1, full_text_tensor_item1))\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9695712327957153\n",
      "0.7536751627922058\n",
      "0.981804609298706\n",
      "\n",
      "====================\n",
      "\n",
      "0.8682611584663391\n",
      "0.9875789880752563\n",
      "0.8751397132873535\n",
      "\n",
      "====================\n",
      "\n",
      "0.9794880747795105\n",
      "0.9585369229316711\n",
      "0.9852710962295532\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 直接舍弃后面部分的内容\n",
    "for text in text_list:\n",
    "    full_text_tensor = tensorlize_texts(model, text)\n",
    "    text_tensor = []  # 3个tensor的列表\n",
    "    for str in text:\n",
    "        substr = str.split()[:50]\n",
    "        sub_sentence = \" \".join(substr)\n",
    "        text_tensor.append(tensorlize_texts(model, sub_sentence))\n",
    "    for full_text_tensor_item, split_text_tensor in zip(full_text_tensor, text_tensor):\n",
    "        print(calculate_cosine_similarity(full_text_tensor_item, split_text_tensor))\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9279798269271851\n",
      "0.7160555124282837\n",
      "0.8789778351783752\n",
      "\n",
      "====================\n",
      "\n",
      "0.8942962288856506\n",
      "0.8469402194023132\n",
      "0.8564712405204773\n",
      "\n",
      "====================\n",
      "\n",
      "0.7474461793899536\n",
      "0.6091711521148682\n",
      "0.6622057557106018\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 计算使用分割后求平均的的文本的余弦相似度\n",
    "# 将段落拆分成2段，然后计算平均后的tensor\n",
    "\n",
    "for text in text_list:\n",
    "    full_text_tensor = tensorlize_texts(model, text)\n",
    "    text_tensor = []  # 3个tensor的列表\n",
    "    for str in text:\n",
    "        text_tensor.append(tensorlize_texts_chunked(model, str, 2))\n",
    "\n",
    "    for full_text_tensor_item, split_text_tensor in zip(full_text_tensor, text_tensor):\n",
    "        print(calculate_cosine_similarity(full_text_tensor_item, split_text_tensor))\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9504979848861694\n",
      "0.7229177951812744\n",
      "0.9135902523994446\n",
      "\n",
      "====================\n",
      "\n",
      "0.8502402305603027\n",
      "0.8935145735740662\n",
      "0.821176290512085\n",
      "\n",
      "====================\n",
      "\n",
      "0.8585348129272461\n",
      "0.8364741802215576\n",
      "0.8617141246795654\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 计算使用分割后求平均的的文本的余弦相似度\n",
    "# 使用滑动窗口将段落拆分之后，计算平均后的tensor\n",
    "text_list = [list1, list2, list3]\n",
    "\n",
    "for text in text_list:\n",
    "    full_text_tensor = tensorlize_texts(model, text)\n",
    "    text_tensor = []  # 3个tensor的列表\n",
    "    for str in text:\n",
    "        text_tensor.append(tensorlize_texts_slideWindow(model, str, 50, 20))\n",
    "\n",
    "    for full_text_tensor_item, split_text_tensor in zip(full_text_tensor, text_tensor):\n",
    "        print(calculate_cosine_similarity(full_text_tensor_item, split_text_tensor))\n",
    "    print(\"\\n====================\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NFT_search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
